{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7c92ba9",
   "metadata": {},
   "source": [
    "# Fixed Parameters in `simpple` Models\n",
    "\n",
    "As shown in previous tutorials, `simpple` model parameters are defined directly as distributions.\n",
    "However, sometimes, we build a model and would like to test it with only a subset of its parameters.\n",
    "In such cases, re-building the entire model is unnecessarily complicated, and freezing certain parameters is preferable.\n",
    "To enable fixed parameters, `simpple` provides a `Fixed` distributions, which is basically a delta function centered on a given parameter value.\n",
    "To keep samplign efficient, these fixed parameters are not treated in the same way as other parameters:\n",
    "\n",
    "- During initialization, `model.fixed_p` and `model.vary_p` are created under the hood to separated fixed and variable parameters.\n",
    "- Fixed parameters are not included in `model.ndim`\n",
    "- Fixed parameters are not included in `model.keys()` by default. They will be included with `model.keys(fixed=True)`\n",
    "- When calling `model.log_likelihood()`, `model.log_prob()` and `model.forward()`, they can optionally be included, but are not required. If they are not included, the fixed value is used.\n",
    "- When calling `model.log_prior()` and `model.prior_transform()`, they are ignored.\n",
    "- When calling `model.log_prior()` and `model.prior_transform()`, `model.nautilus_priors()`, they are ignored.\n",
    "\n",
    "We will explore this functionality below with a simple sinusoidal model.\n",
    "\n",
    "## Simulated Data\n",
    "\n",
    "We will first simulate sinuoidal data that we will fit with a simple forward model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca235c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "\n",
    "def forward_sine(p: dict, x: np.ndarray) -> np.ndarray:\n",
    "    return p[\"A\"] * np.sin(2 * np.pi * x / p[\"P\"] - p[\"phi\"])\n",
    "\n",
    "\n",
    "p_true = {\n",
    "    \"A\": 10.0,\n",
    "    \"P\": 3.0,\n",
    "    \"phi\": np.pi,\n",
    "}\n",
    "\n",
    "x = np.sort(rng.uniform(low=0.0, high=10.0, size=100))\n",
    "x_mod = np.linspace(0.0, 10.0, num=1000)\n",
    "y_true = forward_sine(p_true, x)\n",
    "y_true_mod = forward_sine(p_true, x_mod)\n",
    "\n",
    "yerr = 1\n",
    "y = y_true + yerr * rng.normal(size=x.size)\n",
    "\n",
    "\n",
    "def plot_data():\n",
    "    plt.plot(x_mod, y_true_mod, \"k\", alpha=0.5, zorder=10000, label=\"True model\")\n",
    "    plt.errorbar(x, y, yerr=yerr, label=\"Data\", fmt=\"k.\", mfc=\"w\", capsize=2)\n",
    "    plt.legend(loc=1)\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "\n",
    "\n",
    "plot_data()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5c6d5d",
   "metadata": {},
   "source": [
    "## `simpple` Model without Fixed Parameters\n",
    "\n",
    "First, we will fit the data with a fully variable model where none of the sinusoidal parameters are fixed.\n",
    "This is very similar to the [line-fitting tutorial](./fitting-a-line.ipynb) tutorial, but with a different forward model.\n",
    "\n",
    "We first build our `simpple` model and test it with fixed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060095a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpple.model import ForwardModel\n",
    "import simpple.distributions as sdist\n",
    "\n",
    "\n",
    "def log_likelihood(\n",
    "    p: dict, x: np.ndarray, y: np.ndarray, yerr: np.ndarray\n",
    ") -> np.ndarray:\n",
    "    ymod = forward_sine(p, x)\n",
    "    s2 = yerr**2\n",
    "    return -0.5 * np.sum(np.log(2 * np.pi * s2) + (y - ymod) ** 2 / s2)\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    \"A\": sdist.LogUniform(1e-4, 1e2),\n",
    "    \"P\": sdist.LogUniform(1e-1, 1e1),\n",
    "    \"phi\": sdist.Uniform(0, 2 * np.pi),\n",
    "}\n",
    "model = ForwardModel(parameters, log_likelihood, forward_sine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32347063",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_p = {\"A\": 11.0, \"P\": 3.5, \"phi\": 2.5}\n",
    "\n",
    "plot_data()\n",
    "plt.plot(x_mod, model.forward(test_p, x_mod), label=\"Test model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c352f2",
   "metadata": {},
   "source": [
    "## Sampling of the Model without Fixed Parameters\n",
    "\n",
    "Now that we have a working model, we can sample the parameters with MCMC or nested sampling.\n",
    "Here will use emcee to keep things simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fc684d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emcee\n",
    "\n",
    "nwalkers = 50\n",
    "nsteps = 5000\n",
    "sampler = emcee.EnsembleSampler(nwalkers, model.ndim, model.log_prob, args=(x, y, yerr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d152b1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = np.array(list(test_p.values())) + 1e-4 * rng.normal(size=(nwalkers, model.ndim))\n",
    "_ = sampler.run_mcmc(p0, nsteps, progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac348476",
   "metadata": {},
   "source": [
    "Let us have a look at the chains and the posterior samples, both in parameter space and in model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72b514e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpple.plot import chainplot\n",
    "\n",
    "chainplot(sampler.get_chain(), labels=model.keys())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccbed03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import corner\n",
    "\n",
    "chain = sampler.get_chain(flat=True, discard=1000, thin=5)\n",
    "corner.corner(chain, labels=model.keys(), truths=list(p_true.values()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0638431d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_samples = model.get_posterior_pred(chain.T, 100, x_mod)\n",
    "plt.plot(x_mod, pred_samples[0], \"C0-\", label=\"Posterior samples\")\n",
    "plt.plot(x_mod, pred_samples[1:].T, \"C0-\", alpha=0.2)\n",
    "plot_data()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5602843",
   "metadata": {},
   "source": [
    "## Model with Fixed Parameters\n",
    "\n",
    "Let us say that for some reason, we want to keep one of the parameters fixed.\n",
    "Maybe we have an extremely good constraint from another dataset or we want to test wether a model comparison favors this parameter as fixed or variable.\n",
    "\n",
    "For a simple model like the one used in this tutorial, we could easily re-write the model with one of the parameters fixed.\n",
    "However, as we build more complicated models, re-writing them every time we wish to freeze a parameters quickly becomes inconvenient.\n",
    "\n",
    "As mentioned above, using the `Fixed` distribution will freeze specific parameters in our model.\n",
    "For example, in the model we fix the phase to its true value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b3ea15",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_fix = {\n",
    "    \"A\": sdist.LogUniform(1e-4, 1e2),\n",
    "    \"P\": sdist.LogUniform(1e-1, 1e1),\n",
    "    \"phi\": sdist.Fixed(np.pi),\n",
    "}\n",
    "model_fix = ForwardModel(parameters_fix, log_likelihood, forward_sine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7050d35",
   "metadata": {},
   "source": [
    "As explained above, the number of dimensions and the keys of the model will not account for the fixed parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75da6011",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Keys of the fixed phase model:\", model_fix.keys())\n",
    "print(\"Keys of the fixed phase model (including fixed):\", model_fix.keys(fixed=True))\n",
    "print(\"ndim of the fixed phase model:\", model_fix.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68aadd19",
   "metadata": {},
   "source": [
    "There are also two extra dictionaries, `fixed_p ` and `vary_p`, which are mostly for internal use but can be useful to filter parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128dc98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fixed parameters\", model_fix.fixed_p)\n",
    "print(\"Variable parameters:\", model_fix.vary_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcae70b",
   "metadata": {},
   "source": [
    "The nice thing about this is that we should be able to re-use most of the code from the sampling section with very little modifications.\n",
    "Let us try!\n",
    "\n",
    "We need to change the model name from `model` to `model_fix` first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bbc0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emcee\n",
    "\n",
    "nwalkers = 50\n",
    "nsteps = 5000\n",
    "sampler = emcee.EnsembleSampler(\n",
    "    nwalkers, model_fix.ndim, model_fix.log_prob, args=(x, y, yerr)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048c57d9",
   "metadata": {},
   "source": [
    "And in our test parameters, we must use only the variable parameters to initialize the sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c693cd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_p_vary = {k: v for k, v in test_p.items() if k in model_fix.keys()}\n",
    "p0 = np.array(list(test_p_vary.values())) + 1e-4 * rng.normal(\n",
    "    size=(nwalkers, model_fix.ndim)\n",
    ")\n",
    "_ = sampler.run_mcmc(p0, nsteps, progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc740f0",
   "metadata": {},
   "source": [
    "That worked! Let us see what the results look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11e0559",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpple.plot import chainplot\n",
    "\n",
    "chainplot(sampler.get_chain(), labels=model_fix.keys())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe3051f",
   "metadata": {},
   "source": [
    "For the corner plot, we will use a dictionary to filter the parameters automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d324fd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import corner\n",
    "\n",
    "chain = sampler.get_chain(flat=True, discard=1000, thin=5)\n",
    "chain_dict = dict(zip(model_fix.keys(), chain.T))\n",
    "corner.corner(chain_dict, labels=model_fix.keys(), truths=p_true)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d2eada",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_samples = model_fix.get_posterior_pred(chain.T, 100, x_mod)\n",
    "plt.plot(x_mod, pred_samples[0], \"C0-\", label=\"Posterior samples\")\n",
    "plt.plot(x_mod, pred_samples[1:].T, \"C0-\", alpha=0.2)\n",
    "plot_data()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba56303",
   "metadata": {},
   "source": [
    "That's it!\n",
    "Hopefully this can be useful when building complicated models for various use-cases with `simpple`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
